{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyOkb2dChIPtMZmR+c/x5gIJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bodya-collab/De-Novo-Drug-Design-with-Generative-AI-LSTM-/blob/main/De-Novo-Drug-Design-with-Generative-AI-LST_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Workspace"
      ],
      "metadata": {
        "id": "wnosk5ThJysg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing tools\n",
        "!pip install rdkit\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "print('Done')"
      ],
      "metadata": {
        "id": "-QFjXNFWEx2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing DataFrame"
      ],
      "metadata": {
        "id": "8y43258OKD15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "# 2. 250K mol from ZINC\n",
        "!wget https://raw.githubusercontent.com/aspuru-guzik-group/chemical_vae/master/models/zinc_properties/250k_rndm_zinc_drugs_clean_3.csv -O zinc_250k.csv\n",
        "\n",
        "data = pd.read_csv('zinc_250k.csv')\n",
        "\n",
        "# Smiles column\n",
        "smiles = data['smiles'].tolist()\n",
        "\n",
        "# using only 50000 mol\n",
        "smiles = smiles[:50000]\n",
        "\n",
        "\n",
        "print(\"Example:\", smiles[0])"
      ],
      "metadata": {
        "id": "oNtY05jZFdWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n"
      ],
      "metadata": {
        "id": "pCI2JaOGJrap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary\n",
        "chars = sorted(list(set(\"\".join(smiles))))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "vocab_size = len(chars)\n",
        "max_len = max([len(s) for s in smiles])\n",
        "\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "print(f\"Max length: {max_len}\")\n",
        "print(\"Characters:\", chars)\n",
        "\n",
        "# Function of postion\n",
        "def vectorize(smiles_list):\n",
        "    X = np.zeros((len(smiles_list), max_len, vocab_size), dtype=bool)\n",
        "    Y = np.zeros((len(smiles_list), max_len, vocab_size), dtype=bool)\n",
        "    for i, smile in enumerate(smiles_list):\n",
        "        for t, char in enumerate(smile):\n",
        "            X[i, t, char_to_int[char]] = 1\n",
        "            if t > 0:\n",
        "                Y[i, t-1, char_to_int[char]] = 1 #predicting symbol\n",
        "    return X, Y\n",
        "\n",
        "X, Y = vectorize(smiles)"
      ],
      "metadata": {
        "id": "lhH-hoVTGSuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Brain of code (LSTM)"
      ],
      "metadata": {
        "id": "NHDBZZNhKK4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(max_len, vocab_size)),\n",
        "    layers.LSTM(128, return_sequences=True), # LSTM (memory)\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(vocab_size, activation='softmax') # probability of letter\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qpzlXICXIL-m",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning part"
      ],
      "metadata": {
        "id": "mvVLsl3nKj_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, batch_size=128, epochs=50, validation_split=0.1)"
      ],
      "metadata": {
        "id": "crwp3VxzKui4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ],
      "metadata": {
        "id": "K_kILxMoSIy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # Applying function (random)\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds + 1e-7) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def generate_molecule():\n",
        "    start_index = np.random.randint(0, len(smiles)-1)\n",
        "    seed_sentence = smiles[start_index][:5]\n",
        "    generated = seed_sentence\n",
        "\n",
        "    for i in range(max_len):\n",
        "        x_pred = np.zeros((1, max_len, vocab_size))\n",
        "        for t, char in enumerate(generated):\n",
        "            if char in char_to_int:\n",
        "                x_pred[0, t, char_to_int[char]] = 1.\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0][len(generated)-1]\n",
        "        next_index = sample(preds, temperature=0.2)\n",
        "        next_char = int_to_char[next_index]\n",
        "\n",
        "        generated += next_char\n",
        "        if len(generated) > max_len: break\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Generating 10 and verify\n",
        "valid_mols = []\n",
        "for i in range(20):\n",
        "    smi = generate_molecule()\n",
        "    mol = Chem.MolFromSmiles(smi)\n",
        "    if mol: # if rdkit read = good\n",
        "        valid_mols.append(mol)\n",
        "        print(f\"✅ Valid: {smi}\")\n",
        "    else:\n",
        "        print(f\"❌ Invalid: {smi}\")\n",
        "\n",
        "# Drug-like verification according to Lipinski\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.Chem import QED  # <--- Импортируем QED\n",
        "\n",
        "def check_lipinski(mol):\n",
        "    mw = Descriptors.MolWt(mol)\n",
        "    logp = Descriptors.MolLogP(mol)\n",
        "    hbd = Descriptors.NumHDonors(mol)\n",
        "    hba = Descriptors.NumHAcceptors(mol)\n",
        "\n",
        "    # Counting QED\n",
        "    qed_score = QED.qed(mol)\n",
        "\n",
        "    # Verifing Lipinski\n",
        "    if (150 <= mw <= 500) and (logp <= 5) and (hbd <= 5) and (hba <= 10):\n",
        "        # ВОТ ТУТ мы формируем подпись. Добавили QED в конец строки:\n",
        "        return True, f\"MW:{mw:.0f} LogP:{logp:.1f} QED:{qed_score:.2f}\"\n",
        "    else:\n",
        "        return False, \"Failed\"\n",
        "\n",
        "# filtration\n",
        "good_mols = []\n",
        "legends = []\n",
        "\n",
        "print(\"Mining for drug-like molecules with QED...\")\n",
        "\n",
        "\n",
        "attempts = 0\n",
        "while len(good_mols) < 9 and attempts < 150:\n",
        "    attempts += 1\n",
        "    smi = generate_molecule()\n",
        "    mol = Chem.MolFromSmiles(smi)\n",
        "\n",
        "    if mol:\n",
        "        passed, stats = check_lipinski(mol)\n",
        "        if passed:\n",
        "            good_mols.append(mol)\n",
        "            legends.append(stats)\n",
        "            print(f\" Found: {smi} -> {stats}\")\n",
        "#Draw\n",
        "if len(good_mols) > 0:\n",
        "    print(f\"\\nSuccess! Found {len(good_mols)} drug-like candidates after {attempts} attempts.\")\n",
        "    img = Draw.MolsToGridImage(good_mols, molsPerRow=3, subImgSize=(300, 300), legends=legends)\n",
        "    display(img)\n",
        "else:\n",
        "    print(\"No drug-like molecules found.\")"
      ],
      "metadata": {
        "id": "hSY-kywBSHMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This part was generate by AI assistance in order to solve low productivity and increase calculating potencial"
      ],
      "metadata": {
        "id": "JB32oklCyrTu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd09105e"
      },
      "source": [
        "# Task\n",
        "Increase the number of training epochs in the LSTM model from 20 to 50 to improve the model's ability to generate valid molecules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3823662"
      },
      "source": [
        "## Increase training epochs\n",
        "\n",
        "### Subtask:\n",
        "Increase the number of training epochs for the LSTM model to allow it to learn the SMILES grammar more effectively, aiming to generate more valid molecules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3afaec38"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "The provided information describes a subtask to increase the training epochs of an LSTM model from 20 to 50, aiming to improve its ability to learn SMILES grammar and generate more valid molecules. However, the execution or results of this subtask are not included in the provided solving process. Therefore, no data analysis key findings can be reported at this time.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Execute the described subtask of increasing the LSTM model's training epochs to 50 and evaluate its impact on the validity of generated molecules.\n",
        "*   Analyze the model's performance (e.g., loss, perplexity) during and after the increased training epochs to understand the effectiveness of the change.\n"
      ]
    }
  ]
}